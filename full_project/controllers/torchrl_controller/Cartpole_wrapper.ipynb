{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33820b6ea9075e77",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-27T08:54:27.444106715Z",
     "start_time": "2024-03-27T08:54:25.918598003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostiskak/ntua/Robotalk/tensordict/tensordict/_pytree.py:147: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import gym\n",
    "import torch as th\n",
    "import torch.nn\n",
    "from tensordict import TensorDictBase, TensorDict\n",
    "from torchrl.envs import EnvBase, step_mdp, check_env_specs\n",
    "from torchrl.data import UnboundedContinuousTensorSpec, CompositeSpec, BoundedTensorSpec, BinaryDiscreteTensorSpec, DiscreteTensorSpec\n",
    "\n",
    "\"\"\"\n",
    "# Info for CartPole-v1 test\n",
    "    | Num | Action                 |\n",
    "    |-----|------------------------|\n",
    "    | 0   | Push cart to the left  |\n",
    "    | 1   | Push cart to the right |\n",
    "\n",
    "    | Num | Observation           | Min                 | Max               |\n",
    "    |-----|-----------------------|---------------------|-------------------|\n",
    "    | 0   | Cart Position         | -4.8                | 4.8               |\n",
    "    | 1   | Cart Velocity         | -Inf                | Inf               |\n",
    "    | 2   | Pole Angle            | ~ -0.418 rad (-24°) | ~ 0.418 rad (24°) |\n",
    "    | 3   | Pole Angular Velocity | -Inf                | Inf               |\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CartPoleWrapper(EnvBase):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(device=\"cpu\")\n",
    "        self.env = env  # The underlying environment\n",
    "        # Define the observation and action specs according to the wrapped environment\n",
    "        self.observation_spec = CompositeSpec({\"observation\": BoundedTensorSpec(\n",
    "            low=th.tensor([-4.8, -th.inf, -0.418, -th.inf], dtype=th.float64),\n",
    "            high=th.tensor([4.8, th.inf, 0.418, th.inf], dtype=th.float64))})\n",
    "        self.action_spec = CompositeSpec({\"action\": BinaryDiscreteTensorSpec(1)})\n",
    "        self.reward_spec = CompositeSpec({\"reward\": BoundedTensorSpec(th.tensor([0]), th.inf)})\n",
    "\n",
    "    def _step(self, tensordict: TensorDictBase) -> TensorDictBase:\n",
    "        # Extract the action from the tensordict\n",
    "        action = tensordict.get(\"action\").detach().cpu().numpy()\n",
    "        # Step the underlying environment with the extracted action\n",
    "        obs, reward, term, trunc, info = self.env.step(int(action))\n",
    "        done = term\n",
    "        # print(f\"obs is {obs}\")\n",
    "        # Create a TensorDict to return, including the new observation, reward, and done flag\n",
    "        out = TensorDict({\n",
    "            \"done\": th.tensor([done], dtype=th.bool),\n",
    "            \"observation\": th.tensor(obs, dtype=th.float32),\n",
    "            \"reward\": th.tensor([reward], dtype=th.float32),\n",
    "        }, batch_size=[])\n",
    "        return out\n",
    "\n",
    "    def _reset(self, tensordict: Optional[TensorDictBase] = None, **kwargs) -> TensorDictBase:\n",
    "        # Reset the underlying environment and get the initial observation\n",
    "        obs = self.env.reset()[0]\n",
    "        # Create a TensorDict for the initial state\n",
    "        out = TensorDict({\n",
    "            \"observation\": th.tensor(obs, dtype=th.float32),\n",
    "            \"action\": th.tensor([0], dtype=th.float32),  # Placeholder action\n",
    "            \"done\": th.tensor([False], dtype=th.bool),\n",
    "        }, batch_size=[])\n",
    "        return out\n",
    "\n",
    "    def _set_seed(self, seed: Optional[int]):  # for reproduction of same results\n",
    "        pass\n",
    "        # self.env.seed(seed)  # Assuming the underlying env has a seed method"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Testing the env"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a45d80c663d15e9"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8663/3304887409.py:41: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  obs, reward, term, trunc, info = self.env.step(int(action))\n",
      "2024-03-27 10:54:43,049 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_spec: BinaryDiscreteTensorSpec(\n",
      "    shape=torch.Size([1]),\n",
      "    space=DiscreteBox(n=2),\n",
      "    device=cpu,\n",
      "    dtype=torch.int8,\n",
      "    domain=discrete)\n",
      "\n",
      "\n",
      "dict_items([('observation', tensor([-0.0440,  0.0352, -0.0067,  0.0096])), ('action', tensor([0.])), ('done', tensor([False])), ('terminated', tensor([False]))])\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "gym_env = gym.make('CartPole-v1')\n",
    "env = CartPoleWrapper(gym_env)\n",
    "print(f'action_spec: {env.action_spec}\\n\\n')\n",
    "\n",
    "reset_td = env.reset()\n",
    "print(reset_td.items())\n",
    "\n",
    "step_td = env.step(reset_td)\n",
    "# rollout_td = env.rollout(3)\n",
    "# print(rollout_td)\n",
    "# print('finished rollout')\n",
    "# reset_with_action = env.rand_action(reset_td)\n",
    "# print(reset_with_action[\"action\"])\n",
    "# \n",
    "# data = step_mdp(step_td)\n",
    "# print(data)\n",
    "\n",
    "print(check_env_specs(env))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-27T08:54:43.092080862Z",
     "start_time": "2024-03-27T08:54:43.040425584Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now the transformation and training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8616c3ffc288748b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int8, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        step_count: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        truncated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57649/3304887409.py:41: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  obs, reward, term, trunc, info = self.env.step(int(action))\n"
     ]
    }
   ],
   "source": [
    "from torchrl.envs import StepCounter, TransformedEnv\n",
    "\n",
    "transformed_env = TransformedEnv(env, StepCounter(max_steps=10))  # after 10 steps in truncated the env\n",
    "rollout = transformed_env.rollout(max_steps=100)\n",
    "print(rollout)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T16:44:23.292894698Z",
     "start_time": "2024-03-26T16:44:23.244364326Z"
    }
   },
   "id": "b28b1baf5a124ee4"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [False],\n",
      "        [ True]])\n"
     ]
    }
   ],
   "source": [
    "print(rollout[\"next\", \"truncated\"])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T16:44:23.293326808Z",
     "start_time": "2024-03-26T16:44:23.245165619Z"
    }
   },
   "id": "b635937aea2b7ad7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Now working with Modules"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7095868a221dbdeb"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57649/3304887409.py:41: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  obs, reward, term, trunc, info = self.env.step(int(action))\n"
     ]
    },
    {
     "data": {
      "text/plain": "TensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        loc: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n        next: TensorDict(\n            fields={\n                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n            batch_size=torch.Size([10]),\n            device=None,\n            is_shared=False),\n        observation: Tensor(shape=torch.Size([10, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n        sample_log_prob: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n        scale: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([10]),\n    device=None,\n    is_shared=False)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensordict.nn import TensorDictModule\n",
    "from torchrl.envs.utils import ExplorationType, set_exploration_type\n",
    "module = th.nn.LazyLinear(env.action_spec.shape[-1])\n",
    "policy = TensorDictModule(\n",
    "    module, \n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"actions\"],\n",
    ")\n",
    "\n",
    "# todo why do I get a number for 8 to 10 when i run this? does it mean that it loses at 8 steps?\n",
    "rollout = env.rollout(max_steps=10, policy=policy) \n",
    "rollout\n",
    "\n",
    "from torchrl.modules import Actor\n",
    "\n",
    "\"\"\"\n",
    "    Args:\n",
    "        module (nn.Module): a :class:`~torch.nn.Module` used to map the input to\n",
    "            the output parameter space.\n",
    "        in_keys (iterable of str, optional): keys to be read from input\n",
    "            tensordict and passed to the module. If it\n",
    "            contains more than one element, the values will be passed in the\n",
    "            order given by the in_keys iterable.\n",
    "            Defaults to ``[\"observation\"]``.\n",
    "        out_keys (iterable of str): keys to be written to the input tensordict.\n",
    "            The length of out_keys must match the\n",
    "            number of tensors returned by the embedded module. Using ``\"_\"`` as a\n",
    "            key avoid writing tensor to output.\n",
    "            Defaults to ``[\"action\"]``.\n",
    "\"\"\"\n",
    "\n",
    "policy = Actor(module)\n",
    "rollout = env.rollout(max_steps=10, policy=policy)\n",
    "print(rollout)\n",
    "from torchrl.modules import MLP\n",
    "\n",
    "module = MLP(\n",
    "    out_features=env.action_spec.shape[-1],\n",
    "    num_cells=[32, 64],\n",
    "    activation_class=th.nn.Tanh,\n",
    ")\n",
    "policy = Actor(module)\n",
    "rollout = env.rollout(max_steps=10, policy=policy)\n",
    "rollout\n",
    "from tensordict.nn.distributions import NormalParamExtractor\n",
    "from torch.distributions import Normal\n",
    "from torchrl.modules import ProbabilisticActor\n",
    "\n",
    "backbone = MLP(in_features=4, out_features=2)\n",
    "extractor = NormalParamExtractor()\n",
    "module = th.nn.Sequential(backbone, extractor)\n",
    "td_module = TensorDictModule(module, in_keys=[\"observation\"], out_keys=[\"loc\", \"scale\"])\n",
    "policy = ProbabilisticActor(\n",
    "    td_module,\n",
    "    in_keys=[\"loc\", \"scale\"],\n",
    "    out_keys=[\"action\"],\n",
    "    distribution_class=Normal,\n",
    "    return_log_prob=True\n",
    ")\n",
    "\n",
    "with set_exploration_type(ExplorationType.MEAN):\n",
    "    # takes the mean as action\n",
    "    rollout = env.rollout(max_steps=10, policy=policy)\n",
    "rollout"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T16:56:03.133318339Z",
     "start_time": "2024-03-26T16:56:03.090548652Z"
    }
   },
   "id": "acd673dc264a6689"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c77a98697593fdd0"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57649/3304887409.py:41: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  obs, reward, term, trunc, info = self.env.step(int(action))\n"
     ]
    }
   ],
   "source": [
    "from tensordict.nn import TensorDictSequential\n",
    "from torchrl.modules import EGreedyModule\n",
    "\n",
    "policy = Actor(MLP(4,1,num_cells=[32, 64]))\n",
    "exploration_module = EGreedyModule(\n",
    "    spec=env.action_spec, annealing_num_steps=1000, eps_init=0.5\n",
    ")\n",
    "exploration_policy = TensorDictSequential(policy, exploration_module)\n",
    "with set_exploration_type(ExplorationType.MEAN):\n",
    "    rollout = env.rollout(max_steps=10, policy=exploration_policy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:15:04.627452152Z",
     "start_time": "2024-03-26T17:15:04.566585441Z"
    }
   },
   "id": "b9b35e7e984f4321"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q-value net"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1479c9436ef10af"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([3, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([3]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57649/3304887409.py:41: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  obs, reward, term, trunc, info = self.env.step(int(action))\n"
     ]
    }
   ],
   "source": [
    "from torchrl.modules import QValueModule\n",
    "\n",
    "num_actions = 2\n",
    "value_net = TensorDictModule(\n",
    "    MLP(out_features=num_actions, num_cells=[32, 32]),\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action_value\"],\n",
    ")\n",
    "\n",
    "# policy = TensorDictSequential(\n",
    "#     value_net,\n",
    "#     QValueModule(\n",
    "#         action_space=env.action_spec\n",
    "#     ),   # Reads the \"action_value\" entry by default\n",
    "# )\n",
    "\n",
    "rollout = env.rollout(max_steps=3, policy=policy)   # uses the one from prev cell\n",
    "print(rollout)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:15:09.611562901Z",
     "start_time": "2024-03-26T17:15:09.572898675Z"
    }
   },
   "id": "6929110593215ff5"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorDict(\n",
      "    fields={\n",
      "        loss_actor: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        loss_value: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        pred_value: Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        pred_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        target_value: Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        target_value_max: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        td_error: Tensor(shape=torch.Size([8]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57649/3304887409.py:41: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  obs, reward, term, trunc, info = self.env.step(int(action))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CLASSIC TRAIN LOOP\n",
    "for i in range(n_collections):\n",
    "    data = get_next_batch(env, policy)\n",
    "    for j in range(n_optim):\n",
    "        loss = loss_fn(data)\n",
    "        loss.backward()\n",
    "        optim.step()\"\"\"\n",
    "\n",
    "from torchrl.modules import Actor, MLP, ValueOperator\n",
    "from torchrl.objectives import DDPGLoss\n",
    "\n",
    "n_obs = env.observation_spec[\"observation\"].shape[-1]\n",
    "n_act = env.action_spec.shape[-1]\n",
    "actor = Actor(MLP(in_features=n_obs, out_features=n_act, num_cells=[32, 32]))\n",
    "value_net = ValueOperator(\n",
    "    MLP(in_features=n_obs + n_act, out_features=1, num_cells=[32, 32]),\n",
    "    in_keys=[\"observation\", \"action\"],\n",
    ")\n",
    "ddpg_loss = DDPGLoss(actor_network=actor, value_network=value_net)\n",
    "\n",
    "rollout = env.rollout(max_steps=100, policy=actor)\n",
    "loss_vals = ddpg_loss(rollout)\n",
    "print(loss_vals)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:35:33.811999730Z",
     "start_time": "2024-03-26T17:35:33.786795319Z"
    }
   },
   "id": "647262a6241bd703"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1.0166, grad_fn=<AddBackward0>)"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss = 0\n",
    "for key, val in loss_vals.items():\n",
    "    if key.startswith(\"loss_\"):\n",
    "        total_loss += val\n",
    "total_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:42:30.759489855Z",
     "start_time": "2024-03-26T17:42:30.743619761Z"
    }
   },
   "id": "ffdd53df9f9c583"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[39], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adam\n\u001B[1;32m      2\u001B[0m optim \u001B[38;5;241m=\u001B[39m Adam(ddpg_loss\u001B[38;5;241m.\u001B[39mparameters())\n\u001B[0;32m----> 3\u001B[0m total_loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m      4\u001B[0m optim\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    521\u001B[0m     )\n\u001B[0;32m--> 522\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[1;32m    523\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[1;32m    524\u001B[0m )\n",
      "File \u001B[0;32m~/anaconda3/envs/rl_env/lib/python3.11/site-packages/torch/autograd/__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 266\u001B[0m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    267\u001B[0m     tensors,\n\u001B[1;32m    268\u001B[0m     grad_tensors_,\n\u001B[1;32m    269\u001B[0m     retain_graph,\n\u001B[1;32m    270\u001B[0m     create_graph,\n\u001B[1;32m    271\u001B[0m     inputs,\n\u001B[1;32m    272\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    273\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m    274\u001B[0m )\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "from torch.optim import Adam\n",
    "optim = Adam(ddpg_loss.parameters())\n",
    "total_loss.backward()\n",
    "optim.step()\n",
    "# optim.zero_grad()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:44:16.293301201Z",
     "start_time": "2024-03-26T17:44:16.268646578Z"
    }
   },
   "id": "617a2c8b2194ab08"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ddpg_loss.parameters().__doc__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T17:43:27.732741796Z",
     "start_time": "2024-03-26T17:43:27.717345578Z"
    }
   },
   "id": "be5f1b605ddd4eb6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Collectors"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5fdfb58440beb9c9"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "        3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
      "        4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
      "        7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9,\n",
      "        9, 9, 9, 9, 9, 9, 9, 9])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57649/3304887409.py:41: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  obs, reward, term, trunc, info = self.env.step(int(action))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.envs.utils import RandomPolicy\n",
    "\n",
    "env.set_seed(0)\n",
    "policy = RandomPolicy(env.action_spec)\n",
    "collector = SyncDataCollector(env, policy, frames_per_batch=200, total_frames=-1)\n",
    "\n",
    "for data in collector:\n",
    "    print(data.shape)\n",
    "    break\n",
    "print(data[\"collector\", 'traj_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T18:07:16.222152534Z",
     "start_time": "2024-03-26T18:07:16.121811249Z"
    }
   },
   "id": "8bab43e8e17d4314"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Replay Buffers\n",
    "```\n",
    ">>> for data in collector:\n",
    "...     storage.store(data)\n",
    "...     for i in range(n_optim):\n",
    "...         sample = storage.sample()\n",
    "...         loss_val = loss_fn(sample)\n",
    "...         loss_val.backward()\n",
    "...         optim.step() #\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd17ac614a3557d3"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorDict(\n    fields={\n        action: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.int8, is_shared=False),\n        collector: TensorDict(\n            fields={\n                traj_ids: Tensor(shape=torch.Size([30]), device=cpu, dtype=torch.int64, is_shared=False)},\n            batch_size=torch.Size([30]),\n            device=cpu,\n            is_shared=False),\n        done: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n        next: TensorDict(\n            fields={\n                done: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n                observation: Tensor(shape=torch.Size([30, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n                reward: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n                terminated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n            batch_size=torch.Size([30]),\n            device=cpu,\n            is_shared=False),\n        observation: Tensor(shape=torch.Size([30, 4]), device=cpu, dtype=torch.float32, is_shared=False),\n        terminated: Tensor(shape=torch.Size([30, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n    batch_size=torch.Size([30]),\n    device=cpu,\n    is_shared=False)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchrl.data.replay_buffers import LazyMemmapStorage, ReplayBuffer\n",
    "\n",
    "buffer = ReplayBuffer(storage=LazyMemmapStorage(max_size=1000))\n",
    "indices = buffer.extend(data)\n",
    "\n",
    "sample = buffer.sample(batch_size=30)\n",
    "sample"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T21:22:03.869610885Z",
     "start_time": "2024-03-26T21:22:03.709803406Z"
    }
   },
   "id": "230fd75c2d83684"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Logging"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "963db0e362b64871"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "from torchrl.record import CSVLogger\n",
    "logger = CSVLogger(exp_name='csv_logger_exp')\n",
    "logger.log_scalar(\"my_scalar\", 0.4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-26T21:29:49.010947011Z",
     "start_time": "2024-03-26T21:29:48.963095414Z"
    }
   },
   "id": "dcd014fffbdb3bb6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
